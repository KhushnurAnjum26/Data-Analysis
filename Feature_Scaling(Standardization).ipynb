{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPz/VQ1nZFqaFcdsQpOp3kI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KhushnurAnjum26/Data-Analysis/blob/main/Feature_Scaling(Standardization).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **0. What is Feature Scaling?**\n",
        "\n",
        "Feature Scaling is a technique to normalize or standardize the range of independent variables (features) of data.\n",
        "\n",
        "In most machine learning algorithms, features with different scales can cause problems because many models rely on distance or assume data is centered.\n",
        "\n",
        "\n",
        "Example:\n",
        "Suppose you have the following data:\n",
        "\n",
        "Height (cm)\tWeight (kg)\n",
        "170\t70\n",
        "180\t90\n",
        "\n",
        "\n",
        "Without scaling, \"Weight\" has a smaller numerical range than \"Height\", but that doesnâ€™t mean itâ€™s less important. Algorithms like KNN, SVM, and Gradient Descent-based methods can get biased due to this.\n",
        "\n",
        "\n",
        "# **1. Why do we need Feature Scaling?**\n",
        "\n",
        "Algorithms like KNN, K-Means, SVM, PCA, Logistic Regression use distance or magnitude.\n",
        "\n",
        "\n",
        "Features with larger ranges dominate those with smaller ranges.\n",
        "\n",
        "\n",
        "\n",
        "Gradient Descent may take longer to converge or get stuck.\n",
        "\n",
        "Example:\n",
        "In KNN, if height ranges from 150â€“200 and weight from 1â€“10, the model will care more about height than weightâ€”unless you scale them.\n",
        "\n",
        "\n",
        "\n",
        "# **2. Types of Feature Scaling**\n",
        "\n",
        "There are mainly three common types:\n",
        "\n",
        "## **Min-Max Scaling (Normalization): Scales values between 0 and 1.**\n",
        "\n",
        "ğ‘¥\n",
        "scaled\n",
        "=\n",
        "ğ‘¥\n",
        "âˆ’\n",
        "ğ‘¥\n",
        "min\n",
        "ğ‘¥\n",
        "max\n",
        "âˆ’\n",
        "ğ‘¥\n",
        "min\n",
        "x\n",
        "scaled\n",
        "â€‹\n",
        " =\n",
        "x\n",
        "max\n",
        "â€‹\n",
        " âˆ’x\n",
        "min\n",
        "â€‹\n",
        "\n",
        "xâˆ’x\n",
        "min\n",
        "â€‹\n",
        "\n",
        "â€‹\n",
        "\n",
        "## **Standardization (Z-score Scaling):**\n",
        "\n",
        "ğ‘¥\n",
        "scaled\n",
        "=\n",
        "ğ‘¥\n",
        "âˆ’\n",
        "ğœ‡\n",
        "ğœ\n",
        "x\n",
        "scaled\n",
        "â€‹\n",
        " =\n",
        "Ïƒ\n",
        "xâˆ’Î¼\n",
        "â€‹\n",
        "\n",
        "Here,\n",
        "ğœ‡\n",
        "Î¼ is the mean, and\n",
        "ğœ\n",
        "Ïƒ is the standard deviation.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ğŸ“Œ Formula for Standard Deviation (SD)\n",
        "Standard deviation (\n",
        "ğœ\n",
        "\n",
        "\n",
        "Ïƒ) measures how much values deviate from the mean.\n",
        "\n",
        "For a population:\n",
        "\n",
        "ğœ\n",
        "=\n",
        "1\n",
        "ğ‘\n",
        "âˆ‘\n",
        "ğ‘–\n",
        "=\n",
        "1\n",
        "ğ‘\n",
        "(\n",
        "ğ‘¥\n",
        "ğ‘–\n",
        "âˆ’\n",
        "ğœ‡\n",
        ")\n",
        "2\n",
        "Ïƒ=\n",
        "N\n",
        "1\n",
        "â€‹\n",
        "  \n",
        "i=1\n",
        "âˆ‘\n",
        "N\n",
        "â€‹\n",
        " (x\n",
        "i\n",
        "â€‹\n",
        " âˆ’Î¼)\n",
        "2\n",
        "\n",
        "â€‹\n",
        "\n",
        "For a sample:\n",
        "\n",
        "ğ‘ \n",
        "=\n",
        "1\n",
        "ğ‘›\n",
        "âˆ’\n",
        "1\n",
        "âˆ‘\n",
        "ğ‘–\n",
        "=\n",
        "1\n",
        "ğ‘›\n",
        "(\n",
        "ğ‘¥\n",
        "ğ‘–\n",
        "âˆ’\n",
        "ğ‘¥\n",
        "Ë‰\n",
        ")\n",
        "2\n",
        "s=\n",
        "nâˆ’1\n",
        "1\n",
        "â€‹\n",
        "  \n",
        "i=1\n",
        "âˆ‘\n",
        "n\n",
        "â€‹\n",
        " (x\n",
        "i\n",
        "â€‹\n",
        " âˆ’\n",
        "x\n",
        "Ë‰\n",
        " )\n",
        "2\n",
        "\n",
        "â€‹\n",
        "\n",
        "Where:\n",
        "\n",
        "ğ‘¥\n",
        "ğ‘–\n",
        "x\n",
        "i\n",
        "â€‹\n",
        "  = each data point\n",
        "\n",
        "ğœ‡\n",
        "Î¼ or\n",
        "ğ‘¥\n",
        "Ë‰\n",
        "x\n",
        "Ë‰\n",
        "  = mean\n",
        "\n",
        "ğ‘\n",
        "N or\n",
        "ğ‘›\n",
        "n = number of data points\n",
        "\n",
        "\n",
        "\n",
        "Robust Scaling: Uses median and IQR (Interquartile Range), useful with outliers.\n",
        "\n",
        "\n",
        "## **3. Standardization - Intuition**\n",
        "\n",
        "\n",
        "Standardization transforms data to have zero mean and unit variance. It keeps the shape of the original distribution but shifts and scales it.\n",
        "\n",
        "Useful when data is normally distributed.\n",
        "\n",
        "Doesnâ€™t squash values into a range like [0, 1], but makes data comparable.\n",
        "\n",
        "Example:\n",
        "Original: [50, 60, 70], Mean = 60, Std = 10\n",
        "Standardized: [-1, 0, 1]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# **4. Example**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Letâ€™s scale using Standardization:\n",
        "\n",
        "Original Data:\n",
        "Age\tSalary\n",
        "25\t30,000\n",
        "35\t50,000\n",
        "45\t70,000\n",
        "\n",
        "Step 1: Compute Mean and Std Dev\n",
        "\n",
        "Mean Age = 35, Std = 10\n",
        "\n",
        "Mean Salary = 50,000, Std = 20,000\n",
        "\n",
        "\n",
        "Step 2: Apply Formula\n",
        "\n",
        "AgeÂ (25)\n",
        "=\n",
        "25\n",
        "âˆ’\n",
        "35\n",
        "10\n",
        "=\n",
        "âˆ’\n",
        "1\n",
        "SalaryÂ (30000)\n",
        "=\n",
        "30000\n",
        "âˆ’\n",
        "50000\n",
        "20000\n",
        "=\n",
        "âˆ’\n",
        "1\n",
        "AgeÂ (25)=\n",
        "10\n",
        "25âˆ’35\n",
        "â€‹\n",
        " =âˆ’1\n",
        "SalaryÂ (30000)=\n",
        "20000\n",
        "30000âˆ’50000\n",
        "â€‹\n",
        " =âˆ’1\n",
        "Resulting scaled row: Age = -1, Salary = -1\n",
        "\n",
        "\n",
        "## **5. Impact of Outliers**\n",
        "\n",
        "\n",
        "Outliers can distort the range and mean:\n",
        "\n",
        "Min-Max Scaling is sensitive to outliers.\n",
        "\n",
        "Standardization is less sensitive but still affected.\n",
        "\n",
        "RobustScaler (using median and IQR) is best for outliers.\n",
        "\n",
        "Example:\n",
        "Data: [10, 12, 14, 1000]\n",
        "\n",
        "Min-Max would squash all small values to near 0 because of 1000.\n",
        "\n",
        "Standardization would pull the mean too high.\n",
        "\n",
        "\n",
        "\n",
        "## **6. When to Use Standardization?**\n",
        "\n",
        "\n",
        "âœ… Use Standardization when:\n",
        "\n",
        "## **1. Your Data is Normally Distributed**\n",
        "\n",
        "\n",
        "Explanation:\n",
        "\n",
        "Standardization assumes the data follows a normal (Gaussian) distribution, meaning most values are around the mean and gradually decrease toward the extremes.\n",
        "\n",
        "Why?\n",
        "Standardization transforms the data so that:\n",
        "\n",
        "Mean becomes 0\n",
        "\n",
        "Standard deviation becomes 1\n",
        "\n",
        "Data shape (distribution) remains the same.\n",
        "\n",
        "This is especially helpful when algorithms expect or perform better with normally distributed input.\n",
        "\n",
        "Example:\n",
        "\n",
        "If your dataset has features like human height or test scores, which typically follow a bell curve, standardization helps scale them properly.\n",
        "\n",
        "\n",
        "\n",
        "## **2. You Are Using Distance-Based Algorithms**\n",
        "\n",
        "\n",
        "Examples of distance-based algorithms:\n",
        "\n",
        "K-Nearest Neighbors (KNN)\n",
        "\n",
        "Support Vector Machines (SVM)\n",
        "\n",
        "K-Means Clustering\n",
        "\n",
        "Explanation:\n",
        "\n",
        "These algorithms calculate distances (like Euclidean distance).\n",
        "If features are on different scales, the larger-scale feature dominates, which is unfair.\n",
        "\n",
        "Standardization ensures all features contribute equally to the distance.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## **3. You Want to Retain the Effect of Outliers (to Some Extent)**\n",
        "\n",
        "\n",
        "Explanation:\n",
        "\n",
        "Min-Max scaling compresses all data into a [0, 1] range, which may suppress outliers.\n",
        "\n",
        "Standardization does not suppress outliers, it spreads them in terms of standard deviations.\n",
        "\n",
        "\n",
        "Why?\n",
        "\n",
        "\n",
        "Sometimes, outliers carry important information (e.g., fraud detection, rare diseases).\n",
        "\n",
        "So, if you want to preserve outliers but still scale the data, standardization is a better choice than normalization.\n",
        "\n",
        "\n",
        "\n",
        "ğŸ“Œ Formula for Standardization\n",
        "The formula to standardize a value\n",
        "ğ‘¥\n",
        "x:\n",
        "\n",
        "ğ‘§\n",
        "=\n",
        "ğ‘¥\n",
        "âˆ’\n",
        "ğœ‡\n",
        "ğœ\n",
        "z=\n",
        "Ïƒ\n",
        "xâˆ’Î¼\n",
        "â€‹\n",
        "\n",
        "Where:\n",
        "\n",
        "ğ‘¥\n",
        "x = original value\n",
        "\n",
        "ğœ‡\n",
        "Î¼ = mean of the feature\n",
        "\n",
        "ğœ\n",
        "Ïƒ = standard deviation of the feature\n",
        "\n"
      ],
      "metadata": {
        "id": "7n1MgPOo1GJu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05wdlXeaZ-Cj"
      },
      "outputs": [],
      "source": []
    }
  ]
}